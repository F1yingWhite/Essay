>[多模态学习综述及最新方向 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/389287751)

人类通过多种感觉器官接触世界，例如眼睛、耳朵、触觉。多模态机器学习(Multimodal Machine Learning)研究包含不同模态数据的机器学习问题。常见的模态包括：视觉、文字、声音。它们通常来自于不同的传感器，数据的形成方式和内部结构有很大的区别，例如，图像是自然届存在的连续空间，而文本是依赖人类知识、语法规则组织的离散空间。多模态数据的异质性(heterogeneity)对如何学习多模态间关联性和互补性提出挑战。主要分为以下5种研究
1. **表征**。如何挖掘模态间的互补性或独立性以表征多模态数据。
2. **翻译**。学习一个模态到其他模态的映射。例如：image captioning。
3. **对齐**。将多模态数据的子元素进行对齐。例如phrase grounding任务：将一幅图中的多个物体与一段话中的短语(或单词)进行对齐。在学习表征或翻译时也可能隐式地学习对齐。
4. **融合**。融合两个模态的数据，用来进行某种预测。例如：Visual Question Answering需融合图像和问题来预测答案；Audio-visual speech recognition需融合声音和视频信息用以识别说话内容。
5. **共同学习(co-learning)**。模态间的知识迁移。使用辅助模态训练的网络可以帮助该模态的学习，尤其是该模态数据量较小的情况下。
## 多模态表征
表征学习是多模态任务的基础，其中包含了一些开放性问题，例如：如何结合来源不同的异质数据，如何处理不同模态的不同噪声等级，测试样本的某种模态缺失怎么办。现有多模态表征学习可分为两类：Joint(联合，也称为单塔结构)和Coordinated(协作，双塔结构)。
在Transformer出现之前，不同模态所适用的最佳表征学习模型不同，例如，CNN广泛适用CV领域，LSTM占领NLP领域。较多的多模态工作仍旧局限在使用N个异质网络单独提取N个模态的特征，之后采用Joint或Coordinated结构进行训练。不过这种思路在很快改变，随着越来越多工作证实Transformer在CV和NLP以及Speech领域都可以获得极佳的性能，仅使用Transformer统一多个模态、甚至多个跨模态任务成为可能。
## 跨模态翻译
跨模态翻译的目的是学习如何将源模态映射(map)到目标模态。例如：输入一张图像，我们希望生成一句话描述它，或者输入一句话，我们生成与之匹配的一张图。主流方法分为两类：

**生成式模型**(generative)。抛弃词典，直接生成目标模态的数据。分为三个子类别：
1. 编码-解码器(encoder-decoder)。首先将源模态的数据编码为隐特征 ，后续被解码器用于生成目标模态。以图像描述为例，编码器(一般为CNN+spatial pooling)将图像编码为一个或多个特征向量，进而输入到RNN中以自回归的方式生成单词序列。
2. 基于语法模版，即人为设定多个针对目标模态的语法模版，将模型的预测结果插入模版中作为翻译结果。以图像描述为例，模版定义为 ，其中有四个待替换的插槽。通过不同类型的目标/属性/场景检测器可以获得who did what to whom in aplace等具体单词，进而完成翻译。通过替换进行操作
3. 连续性生成(continuous generation)。它针对源模态与目标模态都为流数据且在时间上严格对齐的任务。以文本合成语音为例，它与图像描述不同，语音数据与文本数据在时间上严格对齐。WaveNet[6]采用了CNN并行预测+CTC loss解决该类问题。当然，编码-解码器理论上也可完成该任务，但需处理数据对齐问题。

## 跨模态对齐
对齐可以作为一个单独的任务，也可以作为其他任务的隐式特征增强手段。多模态对齐可挖掘子元素间的细粒度交互，同时有可解释性，被广泛应用。但多模态对齐面临如下挑战：仅有少量数据集包含显式的对齐标注；跨模态度量难以设计；可能存在多种对齐，也可能存在某些元素无法在其他模态中找到。

## 多模态融合
若测试场景下的输入数据包含多个模态，那么必须面对多模态特征融合。
**模型无关的融合策略：**
前融合：指在模型的浅层(或输入层)将多个模态的特征拼接起来。后融合：独立训练多个模型，在预测层(最后一层)进行融合。混合融合：同时结合前融合和后融合，以及在模型中间层进行特征交互。
**基于模型的融合策略：**
多核学习(Multiple Kernel Learning)是SVM的扩展。SVM通过核函数将输入特征映射到高维空间，使线性不可分问题在高维空间可分。在处理多个输入时，多核处理多个模态特征，使得每个模态都找到其最佳核函数；基于概率图模型利用隐马尔可夫模型或贝叶斯网络建模数据的联合概率分布(生成式)或条件概率(判别式)。基于神经网络的融合。使用LSTM、卷积层、注意力层、门机制、双线性融合等设计序列数据或图像数据的复杂交互。